{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f080e369",
   "metadata": {},
   "source": [
    "오토인코더 만들기."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99746e",
   "metadata": {},
   "source": [
    "1. Dataset\n",
    "    - CIFAR-10\n",
    "2. 이미지를 8x8 혹은 4x4 블록으로 쪼개서 DCT 변환 후, DCT Coeff를 Output으로 내는 AutoEncoder.\n",
    "3. 모델의 Output을 IDCT 해서 원래 이미지가 잘 나오는 지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bb2924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 사용 가능한 GPU 개수: 1\n",
      "현재 선택된 GPU 번호: 0\n",
      "장치 이름: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # 물리적 순서대로 정렬\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"        # 나는 6번 GPU만 보이게 하겠다!\n",
    "\n",
    "import torch\n",
    "print(f\"현재 사용 가능한 GPU 개수: {torch.cuda.device_count()}\")\n",
    "print(f\"현재 선택된 GPU 번호: {torch.cuda.current_device()}\")\n",
    "print(f\"장치 이름: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b395f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 흑백으로 출력함. \n",
    "# dct_ae_cifar10.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 1. DCT / IDCT utilities -> 데이터를 DCT 영역과 이미지 영역을 넘나들 수 있게 함.\n",
    "# -----------------------------\n",
    "\n",
    "def dct2(block):\n",
    "    # 2D DCT (orthonormal)\n",
    "    return dct(dct(block, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "    # ㄴ DCT를 하면서, block은 8*8 이고, axis가 0이면 DCT의 C행렬이 왼쪽에 붙고, axis가 1이면 오른쪽(이건 C의 전치)에 붙는다. \n",
    "    # norm='ortho'는 C전치C가 항등행렬임을 정의한다. 정규화 과정이다.\n",
    "    # block 안에는 그냥 8*8 데이터 저장소일뿐, DCT 되기 전 데이터가 있을수도 있고, 그 후의 데이터가 있을 수도 있다. \n",
    "def idct2(block):\n",
    "    # 2D IDCT (orthonormal)\n",
    "    return idct(idct(block, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "\n",
    "def image_to_dct_blocks(img, block_size=8): # 블록을 8*8로 쪼개기. \n",
    "    \"\"\"\n",
    "    img: (H, W) numpy array -> 높이, 너비. 32*32 흑백 이미지\n",
    "    return: (num_blocks, block_size*block_size) -> (16, 64)\n",
    "    \"\"\"\n",
    "    H, W = img.shape\n",
    "    blocks = [] # 8*8 블록 하나를 DCT 한 뒤, 1차원 64개로 플랫튼. \n",
    "    for i in range(0, H, block_size): # 0 8 16 24\n",
    "        for j in range(0, W, block_size):\n",
    "            block = img[i:i+block_size, j:j+block_size]\n",
    "            blocks.append(dct2(block).flatten()) # 블록 하나를 행이 큰단위, 열이 작은단위로 64개 원소 폄. 그걸 리스트의 한 원소로 추가\n",
    "    return np.stack(blocks) # (16, 64). 16개의 블록 펼쳐진게 쌓여있음. 리스트의 각 원소를 한 행으로 쌓음. \n",
    "                            # 사실 위랑 구조는 같은데, 연산 가능한 행렬로 바꾼 것임. 16행 64열 행렬. \n",
    "\n",
    "# 그냥 위의 역 과정임.\n",
    "def dct_blocks_to_image(blocks, H, W, block_size=8):\n",
    "    \"\"\"\n",
    "    blocks: (num_blocks, block_size*block_size)\n",
    "    return: reconstructed image (H, W)\n",
    "    \"\"\"\n",
    "    img = np.zeros((H, W))\n",
    "    idx = 0\n",
    "    for i in range(0, H, block_size):\n",
    "        for j in range(0, W, block_size):\n",
    "            block = blocks[idx].reshape(block_size, block_size)\n",
    "            img[i:i+block_size, j:j+block_size] = idct2(block)\n",
    "            idx += 1\n",
    "    return img\n",
    "\n",
    "# -----------------------------\n",
    "# 2. AutoEncoder definition\n",
    "# -----------------------------\n",
    "\n",
    "class DCTAutoEncoder(nn.Module): # 블록간 간섭 없고, 완전히 독립적으로 압축, 복원. 64개 들어가서 64개 나옴.\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32), #정보가 강제로 사라졌다가 다시 추청한거라, 기존의 32차원의 정보를 완벽히 복원할 수 없음!!! *중요*\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Dataset (CIFAR-10) -> 컬러 이미지 50,000장을 흑백으로 바꾸고, 연산하기 쉽게 변환. \n",
    "# -----------------------------\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # 단순화를 위해 grayscale. 처리하면 RGB가 흑백사진으로 바뀜. 현재 코드는 컬러로 복원하지 않음.\n",
    "    transforms.ToTensor() # (1, 32, 32)로 변경되고, float32 [0, 1] 범위로 바뀜. 원래는 unit8 [0, 255] 임. \n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Training setup\n",
    "# -----------------------------\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DCTAutoEncoder().to(device)\n",
    "criterion = nn.MSELoss() # 기준은 Mean Squared Error\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) # 인코더 디코더의 모든 파라미터를 최적화. \n",
    "# 옵티마이저는 다음 스텝에서 가중치를 고쳐줌. 모멘트를 고려하는건데, 이건 나중에 따로 학습하기. \n",
    "\n",
    "# -----------------------------\n",
    "# 5. Training loop\n",
    "# -----------------------------\n",
    "\n",
    "epochs = 5 # 전체 이미지를 5바뀌 학습.\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0 # loss 누적값인데, 학습이 진행되는지 확인용. \n",
    "    for img, _ in loader: # _는 라벨인데, AE에서는 사용 안 함. \n",
    "        img = img.squeeze().numpy()  # (32, 32) 원래는 (1, 1, 32, 32)였음. \n",
    "\n",
    "        dct_blocks = image_to_dct_blocks(img)  # (16, 64). 주파주 차원으로 옮김. \n",
    "        dct_blocks = torch.tensor(dct_blocks, dtype=torch.float32).to(device) # 텐서로 바꾸고, GPU에 올림. \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(dct_blocks)\n",
    "        loss = criterion(recon, dct_blocks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() # <- 이거 바꿔서, 평균내거나 오차율 작게 하기. \n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] loss: {total_loss:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Visualization (fixed image) -> 이미지로 복원하는 과정.\n",
    "# -----------------------------\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad(): # 이 블록 안에서는 기울기 계산 안 함. \n",
    "    img, _ = dataset[0]\n",
    "    img = img.squeeze().numpy() # 순수 흑백이미지 생성. \n",
    "\n",
    "    dct_blocks = image_to_dct_blocks(img) # 플랫튼 한 (16, 64) 행렬 생성. \n",
    "    dct_blocks_t = torch.tensor(dct_blocks, dtype=torch.float32).to(device) # 텐서로 바꾸고, GPU에 올림. \n",
    "\n",
    "    recon_blocks = model(dct_blocks_t).cpu().numpy() # 인코딩 디코딩을 모두 통과함. 블록이 출력됨.\n",
    "    recon_img = dct_blocks_to_image(recon_blocks, 32, 32) # (16,64) 블록들을 다시 이미지로 복원. \n",
    "\n",
    "print(\"Original min/max:\", img.min(), img.max()) # 이론적으로 값의 범위는 0~1 사이여야 함. by transforms.ToTensor()\n",
    "print(\"Reconstructed min/max:\", recon_img.min(), recon_img.max()) # DCT계수는 실수 전 범위. \n",
    "\n",
    "plt.figure(figsize=(6,3)) # 원본과 이미지를 보여주는 그림. \n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2) # 복원이미지를 보여주는 그림. \n",
    "plt.title(\"Reconstructed\")\n",
    "plt.imshow(recon_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33786231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "학습 시작 (Device: cuda)\n",
      "Epoch [1/10] | Loss: 0.129430\n",
      "Epoch [2/10] | Loss: 0.016884\n",
      "Epoch [3/10] | Loss: 0.009753\n",
      "Epoch [4/10] | Loss: 0.006657\n",
      "Epoch [5/10] | Loss: 0.004943\n",
      "Epoch [6/10] | Loss: 0.004163\n",
      "Epoch [7/10] | Loss: 0.003774\n",
      "Epoch [8/10] | Loss: 0.003382\n",
      "Epoch [9/10] | Loss: 0.003135\n",
      "Epoch [10/10] | Loss: 0.003001\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 흑백출력인데, GPU 좀더 효과적으로 사용\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# -----------------------------\n",
    "# 1. GPU용 DCT/IDCT 함수 (Matrix Multiplication 방식)\n",
    "# -----------------------------\n",
    "# Scipy 대신 PyTorch 행렬 연산을 사용하여 GPU에서 직접 계산합니다.\n",
    "def get_dct_matrix(n, device):\n",
    "    \"\"\"DCT 변환 행렬 C를 생성합니다.\"\"\"\n",
    "    matrix = torch.zeros((n, n), device=device)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == 0:\n",
    "                matrix[i, j] = 1 / math.sqrt(n)\n",
    "            else:\n",
    "                matrix[i, j] = math.sqrt(2 / n) * math.cos((math.pi * i * (2 * j + 1)) / (2 * n))\n",
    "    return matrix\n",
    "\n",
    "def dct2_gpu(x, dct_mat):\n",
    "    \"\"\"\n",
    "    x: (Batch, 1, 8, 8) \n",
    "    formula: C * x * C^T\n",
    "    \"\"\"\n",
    "    return torch.matmul(torch.matmul(dct_mat, x), dct_mat.t())\n",
    "\n",
    "def idct2_gpu(x, dct_mat):\n",
    "    \"\"\"\n",
    "    formula: C^T * x * C\n",
    "    \"\"\"\n",
    "    return torch.matmul(torch.matmul(dct_mat.t(), x), dct_mat)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. AutoEncoder (배치 처리에 최적화)\n",
    "# -----------------------------\n",
    "class DCTAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (N, 64)\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# -----------------------------\n",
    "# 3. 데이터 준비 및 설정\n",
    "# -----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 512  # 3090의 메모리를 활용하기 위해 크게 설정\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4) # num_workers로 데이터 로딩 가속\n",
    "\n",
    "model = DCTAutoEncoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# DCT 행렬 미리 계산 (8x8 용)\n",
    "dct_mat = get_dct_matrix(8, device)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Training Loop (GPU 가속 버전)\n",
    "# -----------------------------\n",
    "epochs = 10\n",
    "model.train()\n",
    "\n",
    "print(f\"학습 시작 (Device: {device})\")\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for imgs, _ in loader:\n",
    "        # 1. 이미지를 GPU로 이동 (imgs shape: B, 1, 32, 32)\n",
    "        imgs = imgs.to(device)\n",
    "        B = imgs.shape[0]\n",
    "\n",
    "        # 2. 이미지를 8x8 블록으로 쪼개기 (가장 중요한 가속 포인트)\n",
    "        # (B, 1, 32, 32) -> (B, 1, 4, 8, 4, 8) -> (B, 16, 8, 8)\n",
    "        blocks = imgs.unfold(2, 8, 8).unfold(3, 8, 8)\n",
    "        blocks = blocks.contiguous().view(B, -1, 8, 8) # (Batch, 16개블록, 8, 8)\n",
    "        \n",
    "        # 3. GPU에서 배치로 DCT 수행\n",
    "        dct_coeffs = dct2_gpu(blocks, dct_mat) # (B, 16, 8, 8)\n",
    "        dct_input = dct_coeffs.view(-1, 64)   # (B*16, 64) 모델 입력을 위해 펼침\n",
    "\n",
    "        # 4. 학습\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(dct_input)\n",
    "        loss = criterion(recon, dct_input)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {total_loss/len(loader):.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. 결과 확인 (첫 번째 배치 활용)\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_img, _ = dataset[0]\n",
    "    sample_img = sample_img.unsqueeze(0).to(device) # (1, 1, 32, 32)\n",
    "    \n",
    "    # 블록화 및 DCT\n",
    "    b = sample_img.unfold(2, 8, 8).unfold(3, 8, 8).contiguous().view(1, 16, 8, 8)\n",
    "    d = dct2_gpu(b, dct_mat).view(-1, 64)\n",
    "    \n",
    "    # 모델 통과 및 IDCT 복원\n",
    "    r = model(d).view(1, 16, 8, 8)\n",
    "    recon_img_tensor = idct2_gpu(r, dct_mat)\n",
    "    \n",
    "    # (1, 16, 8, 8) 블록을 다시 (32, 32) 이미지로 조립\n",
    "    # 이 과정은 시각화를 위해 간단히 numpy로 처리하겠습니다.\n",
    "    recon_img = torch.zeros((32, 32))\n",
    "    idx = 0\n",
    "    for i in range(0, 32, 8):\n",
    "        for j in range(0, 32, 8):\n",
    "            recon_img[i:i+8, j:j+8] = recon_img_tensor[0, idx]\n",
    "            idx += 1\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1); plt.imshow(sample_img.cpu().squeeze(), cmap='gray'); plt.title(\"Original\")\n",
    "plt.subplot(1,2,2); plt.imshow(recon_img.numpy(), cmap='gray'); plt.title(\"Reconstructed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48eec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[Epoch 1] loss = 27.5767\n",
      "[Epoch 2] loss = 1.7321\n",
      "[Epoch 3] loss = 1.1238\n",
      "[Epoch 4] loss = 0.8349\n",
      "[Epoch 5] loss = 0.7050\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 컬러 출력\n",
    "# dct_ae_cifar10_ycbcr_gpu.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# =========================================================\n",
    "# 1. DCT / IDCT (block-wise)\n",
    "# =========================================================\n",
    "\n",
    "def dct2(block):\n",
    "    return dct(dct(block, axis=-2, norm='ortho'), axis=-1, norm='ortho')\n",
    "\n",
    "def idct2(block):\n",
    "    return idct(idct(block, axis=-2, norm='ortho'), axis=-1, norm='ortho')\n",
    "\n",
    "def image_to_dct_blocks_batch(imgs, block_size=8):\n",
    "    \"\"\"\n",
    "    imgs: (B, H, W)\n",
    "    return: (B, num_blocks, 64)\n",
    "    \"\"\"\n",
    "    B, H, W = imgs.shape\n",
    "    blocks = []\n",
    "\n",
    "    for i in range(0, H, block_size):\n",
    "        for j in range(0, W, block_size):\n",
    "            block = imgs[:, i:i+block_size, j:j+block_size]\n",
    "            block_dct = dct2(block)\n",
    "            blocks.append(block_dct.reshape(B, -1))\n",
    "\n",
    "    return np.stack(blocks, axis=1)  # (B, num_blocks, 64)\n",
    "\n",
    "def dct_blocks_to_image(blocks, H, W, block_size=8):\n",
    "    img = np.zeros((H, W))\n",
    "    idx = 0\n",
    "    for i in range(0, H, block_size):\n",
    "        for j in range(0, W, block_size):\n",
    "            img[i:i+block_size, j:j+block_size] = idct2(\n",
    "                blocks[idx].reshape(block_size, block_size)\n",
    "            )\n",
    "            idx += 1\n",
    "    return img\n",
    "\n",
    "# =========================================================\n",
    "# 2. RGB → YCbCr + 4:2:0 Transform\n",
    "# =========================================================\n",
    "\n",
    "class RGB2YCbCr420:\n",
    "    def __call__(self, img: Image.Image):\n",
    "        ycbcr = np.array(img.convert(\"YCbCr\"), dtype=np.float32)\n",
    "\n",
    "        Y  = ycbcr[:, :, 0] / 255.0\n",
    "        Cb = ycbcr[:, :, 1]\n",
    "        Cr = ycbcr[:, :, 2]\n",
    "\n",
    "        Cb_ds = self.downsample(Cb) / 255.0\n",
    "        Cr_ds = self.downsample(Cr) / 255.0\n",
    "\n",
    "        return {\n",
    "            \"Y\": torch.tensor(Y).unsqueeze(0),\n",
    "            \"Cb\": torch.tensor(Cb_ds),\n",
    "            \"Cr\": torch.tensor(Cr_ds),\n",
    "        }\n",
    "\n",
    "    def downsample(self, ch):\n",
    "        return (\n",
    "            ch[0::2, 0::2] +\n",
    "            ch[1::2, 0::2] +\n",
    "            ch[0::2, 1::2] +\n",
    "            ch[1::2, 1::2]\n",
    "        ) / 4.0\n",
    "\n",
    "# =========================================================\n",
    "# 3. DCT AutoEncoder\n",
    "# =========================================================\n",
    "\n",
    "class DCTAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# =========================================================\n",
    "# 4. Dataset / DataLoader\n",
    "# =========================================================\n",
    "\n",
    "transform = RGB2YCbCr420()\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,      # ★ GPU 사용률 핵심\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 5. Training\n",
    "# =========================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "AE_Y = DCTAutoEncoder().to(device)\n",
    "AE_C = DCTAutoEncoder().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    list(AE_Y.parameters()) + list(AE_C.parameters()),\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for sample, _ in loader:\n",
    "        Y  = sample[\"Y\"].squeeze(1).numpy()     # (B, 32, 32)\n",
    "        Cb = sample[\"Cb\"].numpy()               # (B, 16, 16)\n",
    "        Cr = sample[\"Cr\"].numpy()\n",
    "\n",
    "        dct_Y  = image_to_dct_blocks_batch(Y)\n",
    "        dct_Cb = image_to_dct_blocks_batch(Cb)\n",
    "        dct_Cr = image_to_dct_blocks_batch(Cr)\n",
    "\n",
    "        # (B, blocks, 64) → (B*blocks, 64)\n",
    "        dct_Y  = torch.tensor(dct_Y,  dtype=torch.float32).view(-1, 64).to(device)\n",
    "        dct_Cb = torch.tensor(dct_Cb, dtype=torch.float32).view(-1, 64).to(device)\n",
    "        dct_Cr = torch.tensor(dct_Cr, dtype=torch.float32).view(-1, 64).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        rec_Y  = AE_Y(dct_Y)\n",
    "        rec_Cb = AE_C(dct_Cb)\n",
    "        rec_Cr = AE_C(dct_Cr)\n",
    "\n",
    "        loss = (\n",
    "            criterion(rec_Y, dct_Y)\n",
    "            + 0.25 * (criterion(rec_Cb, dct_Cb) + criterion(rec_Cr, dct_Cr))\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] loss = {total_loss:.4f}\")\n",
    "\n",
    "# =========================================================\n",
    "# 6. Visualization\n",
    "# =========================================================\n",
    "\n",
    "AE_Y.eval()\n",
    "AE_C.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample, _ = dataset[0]\n",
    "\n",
    "    Y  = sample[\"Y\"].squeeze().numpy()\n",
    "    Cb = sample[\"Cb\"].numpy()\n",
    "    Cr = sample[\"Cr\"].numpy()\n",
    "\n",
    "    rec_Y  = dct_blocks_to_image(\n",
    "        AE_Y(torch.tensor(image_to_dct_blocks_batch(Y[None])).view(-1,64).to(device)).cpu().numpy(),\n",
    "        32, 32\n",
    "    )\n",
    "    rec_Cb = dct_blocks_to_image(\n",
    "        AE_C(torch.tensor(image_to_dct_blocks_batch(Cb[None])).view(-1,64).to(device)).cpu().numpy(),\n",
    "        16, 16\n",
    "    )\n",
    "    rec_Cr = dct_blocks_to_image(\n",
    "        AE_C(torch.tensor(image_to_dct_blocks_batch(Cr[None])).view(-1,64).to(device)).cpu().numpy(),\n",
    "        16, 16\n",
    "    )\n",
    "\n",
    "# 업샘플\n",
    "rec_Cb = np.repeat(np.repeat(rec_Cb, 2, axis=0), 2, axis=1)\n",
    "rec_Cr = np.repeat(np.repeat(rec_Cr, 2, axis=0), 2, axis=1)\n",
    "\n",
    "# YCbCr → RGB\n",
    "R = rec_Y + 1.402 * (rec_Cr - 0.5)\n",
    "G = rec_Y - 0.344136 * (rec_Cb - 0.5) - 0.714136 * (rec_Cr - 0.5)\n",
    "B = rec_Y + 1.772 * (rec_Cb - 0.5)\n",
    "\n",
    "rgb_rec = np.clip(np.stack([R, G, B], axis=2), 0, 1)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(np.array(dataset.data[0]) / 255.0)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Reconstructed\")\n",
    "plt.imshow(rgb_rec)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4973041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dct_ae_cifar10_ycbcr_final.py\n",
    "# YCbCr + DCT + AutoEncoder 기반 학습 압축 (최종본)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# =========================================================\n",
    "# 1. DCT / IDCT utilities\n",
    "# =========================================================\n",
    "\n",
    "def dct2(block):\n",
    "    return dct(dct(block, axis=-2, norm='ortho'), axis=-1, norm='ortho')\n",
    "\n",
    "def idct2(block):\n",
    "    return idct(idct(block, axis=-2, norm='ortho'), axis=-1, norm='ortho')\n",
    "\n",
    "def image_to_dct_blocks_batch(imgs, block_size=8):\n",
    "    \"\"\"\n",
    "    imgs: (B, H, W)\n",
    "    return: (B, num_blocks, 64)\n",
    "    \"\"\"\n",
    "    B, H, W = imgs.shape\n",
    "    blocks = []\n",
    "\n",
    "    for i in range(0, H, block_size):\n",
    "        for j in range(0, W, block_size):\n",
    "            block = imgs[:, i:i+block_size, j:j+block_size]\n",
    "            block_dct = dct2(block)\n",
    "            blocks.append(block_dct.reshape(B, -1))\n",
    "\n",
    "    return np.stack(blocks, axis=1)\n",
    "\n",
    "def dct_blocks_to_image(blocks, H, W, block_size=8):\n",
    "    img = np.zeros((H, W))\n",
    "    idx = 0\n",
    "    for i in range(0, H, block_size):\n",
    "        for j in range(0, W, block_size):\n",
    "            img[i:i+block_size, j:j+block_size] = idct2(\n",
    "                blocks[idx].reshape(block_size, block_size)\n",
    "            )\n",
    "            idx += 1\n",
    "    return img\n",
    "\n",
    "# =========================================================\n",
    "# 2. RGB → YCbCr + 4:2:0 Transform\n",
    "# =========================================================\n",
    "\n",
    "class RGB2YCbCr420:\n",
    "    def __call__(self, img: Image.Image):\n",
    "        ycbcr = np.array(img.convert(\"YCbCr\"), dtype=np.float32)\n",
    "\n",
    "        Y  = ycbcr[:, :, 0] / 255.0\n",
    "        Cb = ycbcr[:, :, 1]\n",
    "        Cr = ycbcr[:, :, 2]\n",
    "\n",
    "        Cb_ds = self.downsample(Cb) / 255.0\n",
    "        Cr_ds = self.downsample(Cr) / 255.0\n",
    "\n",
    "        return {\n",
    "            \"Y\":  torch.tensor(Y).unsqueeze(0),   # (1,32,32)\n",
    "            \"Cb\": torch.tensor(Cb_ds),            # (16,16)\n",
    "            \"Cr\": torch.tensor(Cr_ds),            # (16,16)\n",
    "        }\n",
    "\n",
    "    def downsample(self, ch):\n",
    "        return (\n",
    "            ch[0::2, 0::2] +\n",
    "            ch[1::2, 0::2] +\n",
    "            ch[0::2, 1::2] +\n",
    "            ch[1::2, 1::2]\n",
    "        ) / 4.0\n",
    "\n",
    "# =========================================================\n",
    "# 3. Parametric DCT AutoEncoder\n",
    "# =========================================================\n",
    "\n",
    "class DCTAutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        enc = []\n",
    "        in_dim = 64\n",
    "        for h in hidden_dims:\n",
    "            enc += [nn.Linear(in_dim, h), nn.ReLU()]\n",
    "            in_dim = h\n",
    "        enc += [nn.Linear(in_dim, latent_dim)]\n",
    "        self.encoder = nn.Sequential(*enc)\n",
    "\n",
    "        dec = []\n",
    "        in_dim = latent_dim\n",
    "        for h in reversed(hidden_dims):\n",
    "            dec += [nn.Linear(in_dim, h), nn.ReLU()]\n",
    "            in_dim = h\n",
    "        dec += [nn.Linear(in_dim, 64)]\n",
    "        self.decoder = nn.Sequential(*dec)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# =========================================================\n",
    "# 4. Dataset / DataLoader\n",
    "# =========================================================\n",
    "\n",
    "transform = RGB2YCbCr420()\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,      # Colab 안정적\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 5. Training\n",
    "# =========================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "AE_Y = DCTAutoEncoder(\n",
    "    latent_dim=16,\n",
    "    hidden_dims=[48, 32]\n",
    ").to(device)\n",
    "\n",
    "AE_C = DCTAutoEncoder(\n",
    "    latent_dim=4,\n",
    "    hidden_dims=[16]\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    list(AE_Y.parameters()) + list(AE_C.parameters()),\n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "epochs = 150\n",
    "\n",
    "print(\"=== Compression Ratio ===\")\n",
    "orig_size = 32 * 32 * 3\n",
    "latent_size = 16*16 + 4*4 + 4*4\n",
    "print(f\"Original size: {orig_size}\")\n",
    "print(f\"Latent size:   {latent_size}\")\n",
    "print(f\"Compression ratio: {orig_size / latent_size:.2f}:1\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for sample, _ in loader:\n",
    "        Y  = sample[\"Y\"].squeeze(1).numpy()   # (B,32,32)\n",
    "        Cb = sample[\"Cb\"].numpy()             # (B,16,16)\n",
    "        Cr = sample[\"Cr\"].numpy()\n",
    "\n",
    "        dct_Y  = image_to_dct_blocks_batch(Y)\n",
    "        dct_Cb = image_to_dct_blocks_batch(Cb)\n",
    "        dct_Cr = image_to_dct_blocks_batch(Cr)\n",
    "\n",
    "        dct_Y  = torch.tensor(dct_Y,  dtype=torch.float32).view(-1,64).to(device)\n",
    "        dct_Cb = torch.tensor(dct_Cb, dtype=torch.float32).view(-1,64).to(device)\n",
    "        dct_Cr = torch.tensor(dct_Cr, dtype=torch.float32).view(-1,64).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        rec_Y  = AE_Y(dct_Y)\n",
    "        rec_Cb = AE_C(dct_Cb)\n",
    "        rec_Cr = AE_C(dct_Cr)\n",
    "\n",
    "        loss_Y  = criterion(rec_Y, dct_Y)\n",
    "        loss_Cb = criterion(rec_Cb, dct_Cb)\n",
    "        loss_Cr = criterion(rec_Cr, dct_Cr)\n",
    "\n",
    "        loss = loss_Y + 0.25 * (loss_Cb + loss_Cr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"[Epoch {epoch+1:3d}] total loss = {total_loss:.4f}\")\n",
    "\n",
    "# =========================================================\n",
    "# 6. Visualization\n",
    "# =========================================================\n",
    "\n",
    "AE_Y.eval()\n",
    "AE_C.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample, _ = dataset[0]\n",
    "\n",
    "    Y  = sample[\"Y\"].squeeze().numpy()\n",
    "    Cb = sample[\"Cb\"].numpy()\n",
    "    Cr = sample[\"Cr\"].numpy()\n",
    "\n",
    "    rec_Y  = dct_blocks_to_image(\n",
    "        AE_Y(torch.tensor(image_to_dct_blocks_batch(Y[None])).view(-1,64).to(device)).cpu().numpy(),\n",
    "        32, 32\n",
    "    )\n",
    "    rec_Cb = dct_blocks_to_image(\n",
    "        AE_C(torch.tensor(image_to_dct_blocks_batch(Cb[None])).view(-1,64).to(device)).cpu().numpy(),\n",
    "        16, 16\n",
    "    )\n",
    "    rec_Cr = dct_blocks_to_image(\n",
    "        AE_C(torch.tensor(image_to_dct_blocks_batch(Cr[None])).view(-1,64).to(device)).cpu().numpy(),\n",
    "        16, 16\n",
    "    )\n",
    "\n",
    "# 업샘플 (nearest)\n",
    "rec_Cb = np.repeat(np.repeat(rec_Cb, 2, axis=0), 2, axis=1)\n",
    "rec_Cr = np.repeat(np.repeat(rec_Cr, 2, axis=0), 2, axis=1)\n",
    "\n",
    "# YCbCr → RGB\n",
    "R = rec_Y + 1.402 * (rec_Cr - 0.5)\n",
    "G = rec_Y - 0.344136 * (rec_Cb - 0.5) - 0.714136 * (rec_Cr - 0.5)\n",
    "B = rec_Y + 1.772 * (rec_Cb - 0.5)\n",
    "\n",
    "rgb_rec = np.clip(np.stack([R, G, B], axis=2), 0, 1)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(np.array(dataset.data[0]) / 255.0)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Reconstructed\")\n",
    "plt.imshow(rgb_rec)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefa9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중간에 DCT랑 이미지 출력\n",
    "\n",
    "# dct_ae_cifar10_ycbcr_with_dct_visualization.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# =========================================================\n",
    "# 1. DCT / IDCT utilities\n",
    "# =========================================================\n",
    "\n",
    "def dct2(block):\n",
    "    return dct(dct(block, axis=-2, norm='ortho'), axis=-1, norm='ortho')\n",
    "\n",
    "def idct2(block):\n",
    "    return idct(idct(block, axis=-2, norm='ortho'), axis=-1, norm='ortho')\n",
    "\n",
    "def image_to_dct_blocks_batch(imgs, block_size=8):\n",
    "    B, H, W = imgs.shape\n",
    "    blocks = []\n",
    "    for i in range(0, H, block_size):\n",
    "        for j in range(0, W, block_size):\n",
    "            block = imgs[:, i:i+block_size, j:j+block_size]\n",
    "            block_dct = dct2(block)\n",
    "            blocks.append(block_dct.reshape(B, -1))\n",
    "    return np.stack(blocks, axis=1)\n",
    "\n",
    "def dct_blocks_to_image(blocks, H, W, block_size=8):\n",
    "    img = np.zeros((H, W))\n",
    "    idx = 0\n",
    "    for i in range(0, H, block_size):\n",
    "        for j in range(0, W, block_size):\n",
    "            img[i:i+block_size, j:j+block_size] = idct2(\n",
    "                blocks[idx].reshape(block_size, block_size)\n",
    "            )\n",
    "            idx += 1\n",
    "    return img\n",
    "\n",
    "# =========================================================\n",
    "# 2. RGB → YCbCr + 4:2:0 Transform\n",
    "# =========================================================\n",
    "\n",
    "class RGB2YCbCr420:\n",
    "    def __call__(self, img: Image.Image):\n",
    "        ycbcr = np.array(img.convert(\"YCbCr\"), dtype=np.float32)\n",
    "\n",
    "        Y  = ycbcr[:, :, 0] / 255.0\n",
    "        Cb = ycbcr[:, :, 1]\n",
    "        Cr = ycbcr[:, :, 2]\n",
    "\n",
    "        Cb_ds = self.downsample(Cb) / 255.0\n",
    "        Cr_ds = self.downsample(Cr) / 255.0\n",
    "\n",
    "        return {\n",
    "            \"Y\":  torch.tensor(Y).unsqueeze(0),\n",
    "            \"Cb\": torch.tensor(Cb_ds),\n",
    "            \"Cr\": torch.tensor(Cr_ds),\n",
    "        }\n",
    "\n",
    "    def downsample(self, ch):\n",
    "        return (\n",
    "            ch[0::2, 0::2] +\n",
    "            ch[1::2, 0::2] +\n",
    "            ch[0::2, 1::2] +\n",
    "            ch[1::2, 1::2]\n",
    "        ) / 4.0\n",
    "\n",
    "# =========================================================\n",
    "# 3. Parametric DCT AutoEncoder\n",
    "# =========================================================\n",
    "\n",
    "class DCTAutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        enc = []\n",
    "        in_dim = 64\n",
    "        for h in hidden_dims:\n",
    "            enc += [nn.Linear(in_dim, h), nn.ReLU()]\n",
    "            in_dim = h\n",
    "        enc += [nn.Linear(in_dim, latent_dim)]\n",
    "        self.encoder = nn.Sequential(*enc)\n",
    "\n",
    "        dec = []\n",
    "        in_dim = latent_dim\n",
    "        for h in reversed(hidden_dims):\n",
    "            dec += [nn.Linear(in_dim, h), nn.ReLU()]\n",
    "            in_dim = h\n",
    "        dec += [nn.Linear(in_dim, 64)]\n",
    "        self.decoder = nn.Sequential(*dec)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# =========================================================\n",
    "# 4. Dataset / DataLoader\n",
    "# =========================================================\n",
    "\n",
    "transform = RGB2YCbCr420()\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 5. Training setup\n",
    "# =========================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "AE_Y = DCTAutoEncoder(latent_dim=16, hidden_dims=[48, 32]).to(device)\n",
    "AE_C = DCTAutoEncoder(latent_dim=4,  hidden_dims=[16]).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    list(AE_Y.parameters()) + list(AE_C.parameters()),\n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "epochs = 100\n",
    "vis_epochs = [10, 50, 100]\n",
    "\n",
    "# 고정 시각화용 샘플\n",
    "fixed_sample, _ = dataset[0]\n",
    "fixed_Y  = fixed_sample[\"Y\"].squeeze().numpy()\n",
    "fixed_Cb = fixed_sample[\"Cb\"].numpy()\n",
    "fixed_Cr = fixed_sample[\"Cr\"].numpy()\n",
    "\n",
    "# =========================================================\n",
    "# 6. Training + Visualization\n",
    "# =========================================================\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for sample, _ in loader:\n",
    "        Y  = sample[\"Y\"].squeeze(1).numpy()\n",
    "        Cb = sample[\"Cb\"].numpy()\n",
    "        Cr = sample[\"Cr\"].numpy()\n",
    "\n",
    "        dct_Y  = torch.tensor(\n",
    "            image_to_dct_blocks_batch(Y),\n",
    "            dtype=torch.float32\n",
    "        ).view(-1,64).to(device)\n",
    "\n",
    "        dct_Cb = torch.tensor(\n",
    "            image_to_dct_blocks_batch(Cb),\n",
    "            dtype=torch.float32\n",
    "        ).view(-1,64).to(device)\n",
    "\n",
    "        dct_Cr = torch.tensor(\n",
    "            image_to_dct_blocks_batch(Cr),\n",
    "            dtype=torch.float32\n",
    "        ).view(-1,64).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        rec_Y  = AE_Y(dct_Y)\n",
    "        rec_Cb = AE_C(dct_Cb)\n",
    "        rec_Cr = AE_C(dct_Cr)\n",
    "\n",
    "        loss = (\n",
    "            criterion(rec_Y, dct_Y)\n",
    "            + 0.25 * (criterion(rec_Cb, dct_Cb) + criterion(rec_Cr, dct_Cr))\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1:3d}] loss = {total_loss:.4f}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # Visualization at selected epochs\n",
    "    # =====================================================\n",
    "\n",
    "    if (epoch+1) in vis_epochs:\n",
    "        AE_Y.eval()\n",
    "        AE_C.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dct_Y_fixed = image_to_dct_blocks_batch(fixed_Y[None])[0]\n",
    "\n",
    "            rec_Y_img = dct_blocks_to_image(\n",
    "                AE_Y(\n",
    "                    torch.tensor(dct_Y_fixed, dtype=torch.float32)\n",
    "                    .to(device)\n",
    "                ).cpu().numpy(),\n",
    "                32, 32\n",
    "            )\n",
    "\n",
    "            rec_Cb_img = dct_blocks_to_image(\n",
    "                AE_C(\n",
    "                    torch.tensor(\n",
    "                        image_to_dct_blocks_batch(fixed_Cb[None])[0],\n",
    "                        dtype=torch.float32\n",
    "                    ).to(device)\n",
    "                ).cpu().numpy(),\n",
    "                16, 16\n",
    "            )\n",
    "\n",
    "            rec_Cr_img = dct_blocks_to_image(\n",
    "                AE_C(\n",
    "                    torch.tensor(\n",
    "                        image_to_dct_blocks_batch(fixed_Cr[None])[0],\n",
    "                        dtype=torch.float32\n",
    "                    ).to(device)\n",
    "                ).cpu().numpy(),\n",
    "                16, 16\n",
    "            )\n",
    "\n",
    "        # 업샘플\n",
    "        rec_Cb_img = np.repeat(np.repeat(rec_Cb_img, 2, axis=0), 2, axis=1)\n",
    "        rec_Cr_img = np.repeat(np.repeat(rec_Cr_img, 2, axis=0), 2, axis=1)\n",
    "\n",
    "        # YCbCr → RGB\n",
    "        R = rec_Y_img + 1.402 * (rec_Cr_img - 0.5)\n",
    "        G = rec_Y_img - 0.344136 * (rec_Cb_img - 0.5) - 0.714136 * (rec_Cr_img - 0.5)\n",
    "        B = rec_Y_img + 1.772 * (rec_Cb_img - 0.5)\n",
    "        rgb_rec = np.clip(np.stack([R, G, B], axis=2), 0, 1)\n",
    "\n",
    "        # DCT 시각화 (첫 번째 블록)\n",
    "        dct_block = dct_Y_fixed[0].reshape(8,8)\n",
    "        dct_vis = np.log(np.abs(dct_block) + 1e-6)\n",
    "\n",
    "        plt.figure(figsize=(9,3))\n",
    "        plt.suptitle(f\"Epoch {epoch+1}\", fontsize=14)\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.title(\"Y DCT (log-scale)\")\n",
    "        plt.imshow(dct_vis, cmap=\"gray\")\n",
    "        plt.colorbar()\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.title(\"Reconstructed Y\")\n",
    "        plt.imshow(rec_Y_img, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.title(\"Reconstructed RGB\")\n",
    "        plt.imshow(rgb_rec)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        AE_Y.train()\n",
    "        AE_C.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f805e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dct_ae_dct_before_decoder_visualization.py\n",
    "# Decoder 출력 DCT 변화 시각화 (epoch=50)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# =========================================================\n",
    "# DCT / IDCT\n",
    "# =========================================================\n",
    "\n",
    "def dct2(block):\n",
    "    return dct(dct(block, axis=-2, norm='ortho'), axis=-1, norm='ortho')\n",
    "\n",
    "def image_to_dct_blocks(img, block_size=8):\n",
    "    H, W = img.shape\n",
    "    blocks = []\n",
    "    for i in range(0, H, block_size):\n",
    "        for j in range(0, W, block_size):\n",
    "            block = img[i:i+block_size, j:j+block_size]\n",
    "            blocks.append(dct2(block).flatten())\n",
    "    return np.stack(blocks)\n",
    "\n",
    "# =========================================================\n",
    "# RGB → YCbCr (Y only)\n",
    "# =========================================================\n",
    "\n",
    "class RGB2Y:\n",
    "    def __call__(self, img: Image.Image):\n",
    "        y = np.array(img.convert(\"YCbCr\"), dtype=np.float32)[:,:,0] / 255.0\n",
    "        return torch.tensor(y).unsqueeze(0)\n",
    "\n",
    "# =========================================================\n",
    "# DCT AutoEncoder\n",
    "# =========================================================\n",
    "\n",
    "class DCTAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# =========================================================\n",
    "# Dataset\n",
    "# =========================================================\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=RGB2Y()\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DCTAutoEncoder().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 고정 이미지\n",
    "fixed_img, _ = dataset[0]\n",
    "fixed_img = fixed_img.squeeze().numpy()\n",
    "fixed_dct = image_to_dct_blocks(fixed_img)\n",
    "fixed_block = fixed_dct[0]   # 첫 번째 8×8 블록\n",
    "\n",
    "# =========================================================\n",
    "# Training + DCT tracking\n",
    "# =========================================================\n",
    "\n",
    "epochs = 50\n",
    "checkpoints = [1, 10, 25, 50]\n",
    "dct_history = {}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for img, _ in dataset:\n",
    "        img = img.squeeze().numpy()\n",
    "        dct_blocks = image_to_dct_blocks(img)\n",
    "        dct_blocks = torch.tensor(dct_blocks, dtype=torch.float32).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(dct_blocks)\n",
    "        loss = criterion(recon, dct_blocks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # DCT 변화 저장\n",
    "    if (epoch+1) in checkpoints:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            dct_in = torch.tensor(fixed_block, dtype=torch.float32).to(device)\n",
    "            dct_out = model(dct_in.unsqueeze(0)).cpu().numpy()[0]\n",
    "            dct_history[epoch+1] = dct_out\n",
    "\n",
    "    print(f\"[Epoch {epoch+1:2d}] done\")\n",
    "\n",
    "# =========================================================\n",
    "# Visualization\n",
    "# =========================================================\n",
    "\n",
    "plt.figure(figsize=(12, 3*len(checkpoints)))\n",
    "\n",
    "for i, ep in enumerate(checkpoints):\n",
    "    dct_out = dct_history[ep]\n",
    "\n",
    "    dct_in_img  = np.log(np.abs(fixed_block.reshape(8,8)) + 1e-6)\n",
    "    dct_out_img = np.log(np.abs(dct_out.reshape(8,8)) + 1e-6)\n",
    "    dct_diff    = np.log(np.abs(dct_out - fixed_block).reshape(8,8) + 1e-6)\n",
    "\n",
    "    plt.subplot(len(checkpoints), 3, 3*i+1)\n",
    "    plt.title(f\"Epoch {ep} | Input DCT\")\n",
    "    plt.imshow(dct_in_img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(len(checkpoints), 3, 3*i+2)\n",
    "    plt.title(\"Reconstructed DCT\")\n",
    "    plt.imshow(dct_out_img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(len(checkpoints), 3, 3*i+3)\n",
    "    plt.title(\"|DCT_out - DCT_in|\")\n",
    "    plt.imshow(dct_diff, cmap=\"hot\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
