{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc4ddf7",
   "metadata": {},
   "source": [
    "MNIST를 활용한 딥러닝 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d523001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 사용 가능한 GPU 개수: 1\n",
      "현재 선택된 GPU 번호: 0\n",
      "장치 이름: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # 물리적 순서대로 정렬\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"        # 나는 6번 GPU만 보이게 하겠다!\n",
    "\n",
    "import torch\n",
    "print(f\"현재 사용 가능한 GPU 개수: {torch.cuda.device_count()}\")\n",
    "print(f\"현재 선택된 GPU 번호: {torch.cuda.current_device()}\")\n",
    "print(f\"장치 이름: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbf20c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#### 매!!우!! 중요한 내용임!!! 이해하기\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1개의 흑백사진과, 6개의 필터. 그리고 그 필터 크기는 5*5크기\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 6개의 입력 채널, 16개의 출력을 해주는 필터들. 그리고 그 필터 5*5크기\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension. 필요한 정보 조합해서 400개를 120개로 줄임. 학습된 가중치 기준.\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
    "        c1 = F.relu(self.conv1(input)) # 입력을 6개의 필터에 통과시키고, 각각 레루 적용\n",
    "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n",
    "        s2 = F.max_pool2d(c1, (2, 2)) # 2*2 크기의 필터, 근데 2칸씩 이동하고, 그 안에서 가장 큰 수만 남기는 필터. 사이즈는 가로세로 1/2씩\n",
    "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 10, 10) Tensor\n",
    "        c3 = F.relu(self.conv2(s2)) # s2를 16개의 필터 통과시키고, 렐류 적용.\n",
    "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n",
    "        s4 = F.max_pool2d(c3, 2) # c3를 2*2 필터로 1/2 크기로 줄임.\n",
    "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
    "        s4 = torch.flatten(s4, 1) # -->> 이걸 한 줄로 펴줌. 단, N의 정보는 빼고.\n",
    "        # Fully connected layer F5: (N, 400) Tensor input,\n",
    "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
    "        f5 = F.relu(self.fc1(s4)) # 그 정보를 줄이고 렐루 적용. 근거는 데이터로부터 학습된 가중치 기준으로.\n",
    "        # Fully connected layer F6: (N, 120) Tensor input,\n",
    "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
    "        f6 = F.relu(self.fc2(f5)) # 다시 줄이고 렐루 적용\n",
    "        # Fully connected layer OUTPUT: (N, 84) Tensor input, and\n",
    "        # outputs a (N, 10) Tensor\n",
    "        output = self.fc3(f6) # 다시 줄이고 렐루 적용\n",
    "        return output\n",
    "# 굉장히 큰 수를 숫자 10개로 줄였다. 이제 10개의 이미지 종류중에서 뭐에 해당하는지 맞춰볼 수 있다.\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad185157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight. 필터 6개이고, 각 1개당 5*5이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36ef41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([ # 합성함수를 해 준다. 매번 두 함수 써야 했는데, 두 개 함성해줌.\n",
    "    transforms.Resize(32), # 고무줄처럼 늘려서 다시 작성함. \n",
    "    transforms.ToTensor(), # 픽셀값을 0~1사이의 정규화된 float으로 변환해줌. + 채널(흑백은 1. 이 실험에서 바뀔 일 없음.) 차원도 추가함. \n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST( # MNIST 라는 클래스를 따라갈 수 있도록 새로 지정해 준 것일 뿐이다. \n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform # MNIST 클래스의 생성자 인자 중, transform 에는 우리가 위에 만들어둔 transform을 끼워넣자!\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST( # 이미지 꺼내는 방법을 정의한 객체\n",
    "    root='./data',\n",
    "    train=False, # 이건 테스트 셋임.\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader( # 클래스를 호출해서 만든 객체를 담음. dataset과 다르게 dataloader는 여러 장을 묶어서 반복하는 법.\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ") # 매 epoch마다 전체 데이터 섞고, 앞에 64개 잘러서 묶음.\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ") # 재현성 때문에 안 섞고, 어차피 모든 데이터를 사용할 거라 안 섞는 이유가 됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea19144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3058, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss() # -->> 이 부분. 소프트 맥스로 확률이 몰리게끔 도와줌.\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    images = images.to(device) # 같은 GPU위에 올라가 있어야 연산이 가능한데, CPU에 올라가 있길래 변경해줌.\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = net(images)     # (N, 10)\n",
    "    loss = criterion(outputs, labels)  # labels: (N,), 정수 0~9\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6f5333e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0008, -0.0018,  0.0016,  0.0029, -0.0007, -0.0008], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 학습에서 쓰이는 grd는 그 step동안 backward로 만들어진 grad의 합이다. 그래서 계속 누적이 되는 것임.\n",
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "# 이걸 이해하면, 이후에 옵티마이저를 더 쉽게 이해할 수 있음.\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward() # 61,706차원의 가중치공간에서, 각각의 축으로 미분한 값을 모아 그라디언트 벡터를 61,706차원에 하나 만들었다.\n",
    "#그리고 아미지 N장 중 미니배치 4장만 골라서 그라디언트를 구하면, 4개 함수의 그라디언트의 합으로 loss.backward가 만들어지고, 전파하면 됨.\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e2c72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate) # 실제로 이렇게 돌아가지만, 다른 모델에서도 똑같이 돌아가게 하기 위해서 optimizer 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9) #모멘텀은 관성임.\n",
    "\n",
    "for images, labels in train_loader: # train_loader에서 images, labels를 하나씩 꺼내서 반복하겠다는 의미. \n",
    "    images = images.to(device) # 이미지 60,000장인데, 배치크기 64니까 총 938번 돌음.\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = net(images)\n",
    "    loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953784f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 0.4933\n",
      "[Epoch 2] Loss: 0.0844\n",
      "[Epoch 3] Loss: 0.0575\n",
      "[Epoch 4] Loss: 0.0457\n",
      "[Epoch 5] Loss: 0.0356\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5 # epoch는 전체 데이터셋을 한 번 도는 걸 몇번하는지이다. \n",
    "                # 부연 설명을 하자면, 6만장을 앞에서부터 64개씩 끊어서 사용하고 셔플 후 다시 6만장을 끊어 사용함. 이걸 5번 반복함.\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()          # grad 초기화\n",
    "        outputs = net(images)          # forward\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()                # backward\n",
    "        optimizer.step()               # update\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df3911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.77%\n"
     ]
    }
   ],
   "source": [
    "# 이제 학습이 끝난 모델의 성능을 평가하는 단계.\n",
    "\n",
    "correct = 0 #맞힌 샘플 개수\n",
    "total = 0 # 전체 샘플 개수\n",
    "\n",
    "with torch.no_grad(): # 가중치 업데이트를 막아놓음.\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = net(images) # 정확히는 N개의 이미지, 10개의 차원이다. \n",
    "        _, predicted = torch.max(outputs, 1) # 결과중에 각 이미지마다 가장 큰 값을 고른다.\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item() # 가장 큰 값이 실제 정답과 맞는지 비교한다.\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "var",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
